# -*- coding: utf-8 -*-
"""actividad12_cozzini.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T6TxMSMAtlsJukZ2zpvNn5JzEsWWcLad

Hay que construir 1 notebook

para el mismo problema de clasificación de texto utilizado la semana anterior

donde se utilicen redes neuronales recurrentes

Hay que aplicar al menos una **opción avanzada** en el uso de RNN: como el **apilamiento de redes recurrentes** o el uso de **redes recurrentes bidireccionales**

Los resultados de las evaluaciones de las distintas técnicas utilizadas deben mostrar la **matriz de confusión** y las **métricas** presentadas anteriormente
"""

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

import keras
keras.__version__

emociones_file_path = "/content/Emotion_final.csv"
emociones_data = pd.read_csv(emociones_file_path)

emociones_data.head()

#El siguiente código nos permite obtener el número de clases en las que se deben clasificar los datos, lo que nos ayuda a conocer las categorías o clases presentes en los datos para luego clasificarlos

distinct_emotions = emociones_data['Emotion'].unique() #esta linea me permite encontrar las clases distintas en la columna 'Emotion' de 'emociones_data'
print("Mis clases:", distinct_emotions)

#se trata de un problema de clasificacion multiclase
#ya que, como puedo ver del output del codigo siguiente, tengo 6 clases en las cuales clasificar a mis textos
len(distinct_emotions)

"""El dataset que utilizaremos para entrenar nuestro clasificador contiene 21,450 textos breves, con una longitud promedio de 18 palabras por texto. Cada texto está clasificado en una de seis emociones: sadness (tristeza), anger (enfado), love (amor), surprise (sorpresa), fear ( miedo) y happy (feliz)."""

#divido los textos desde las clases (etiquetas) en las que tengo que clasificarlos

textos = emociones_data['Text']
etiquetas= emociones_data['Emotion']

#preprocesamos el texto para preparar los datos antes de ser alimentados a un modelo de aprendizaje automático

#Importamos las librerías necesarias para el preprocesamiento del texto
import re #para expresiones regulares
import nltk #para el procesamiento de lenguaje natural
from nltk.corpus import stopwords #stopwords de NLTK para filtrar las palabras vacías

#Inicializamos el tokenizador y descargamos las stopwords en inglés usando NLTK
wpt = nltk.WordPunctTokenizer()
nltk.download('stopwords')
stop_words = nltk.corpus.stopwords.words('english')

#Definimos una función que normaliza el texto
def normalize_document(doc):
  #Convierte el texto a minúsculas y elimina caracteres especiales y espacios en blanco
    doc = re.sub(r'[^a-zA-Z\s]', '', doc, re.I)
    doc = doc.lower()
    doc = doc.strip()
    #Tokeniza el texto en palabras individuales
    tokens = wpt.tokenize(doc)
    # Filtra las stopwords para eliminar palabras comunes que no aportan valor semántico
    filtered_tokens = [token for token in tokens if token not in stop_words]
    # Re-crea el documento a partir de las palabras filtradas
    doc = ' '.join(filtered_tokens)
    return doc

normalize_corpus= np.vectorize(normalize_document)
#Vectorizamos la función normalize_document para poder aplicarla eficientemente a cada elemento de un array o serie de datos


norm_corpus = normalize_corpus(textos) #Aplicamos la función de normalización al conjunto de textos

#dividimos los datos en conjunto de test (prueba) y conjunto de train (entrenamiento)
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(textos, etiquetas, test_size=0.2, random_state=42)

#creamos tambien un validation set
nuevo_X_train, X_val, nuevo_y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)
print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)

#Convierto a mis textos en secuencias de índices de palabras, con los cuales luego alimentaré a mi red neuronal

from tensorflow.keras.preprocessing.text import Tokenizer #El Tokenizer se encarga de tokenizar el texto: divide las frases en palabras y les asigna un índice numérico
from tensorflow.keras.preprocessing.sequence import pad_sequences #pad_sequences sirve para convertir listas de diferentes longitudes (secuencias de palabras) en listas del mismo tamaño, añadiendo ceros al final (o al principio)

max_features = 10000 #Este valor indica el número máximo de palabras únicas que se tendrán en cuenta en el vocabulario
maxlen = 20
tokenizer = Tokenizer(num_words=max_features) #Se crea una instancia de la clase Tokenizer
# `num_words=max_features` indica el número máximo de palabras únicas que se tendrán en cuenta en el vocabulario
tokenizer.fit_on_texts(nuevo_X_train) #Ajusta el tokenizador al texto en nuevo_X_train, que es el conjunto de datos de entrenamiento
#Toma cada palabra del texto, construye un vocabulario y asigna un índice único a cada palabra según su frecuencia (las palabras más frecuentes tienen índices más bajos)

vocabolario = tokenizer.word_index #Devuelve un diccionario donde las claves son palabras y los valores son los índices asignados por el tokenizador
print("Vocabolario:", vocabolario)

X_train_sequencias = tokenizer.texts_to_sequences(nuevo_X_train) #Convierte cada texto en nuevo_X_train en una secuencia de índices
#X_train_sequencias es una lista de listas, donde cada lista contiene los índices de las palabras de cada texto en nuevo_X_train

#Convertimos los textos de validación (X_val) y de prueba (X_test) en secuencias de índices usando el mismo tokenizador que se ajustó con nuevo_X_train
X_val_sequencias = tokenizer.texts_to_sequences(X_val)
X_test_sequencias = tokenizer.texts_to_sequences(X_test)

#pad_sequences: Ajusta las secuencias a la misma longitud. Esto es necesario porque los modelos de aprendizaje automático requieren que todas las entradas tengan el mismo tamaño
#El resultado es un array donde cada fila tiene la misma longitud
X_train_sequencias_padded = pad_sequences(X_train_sequencias, padding='post', maxlen=maxlen)
X_val_sequencias_padded = pad_sequences(X_val_sequencias, padding='post', maxlen=maxlen )
X_test_sequencias_padded = pad_sequences(X_test_sequencias, padding='post', maxlen=maxlen)

#Convertimos las secuencias de entrenamiento, validación y prueba a arrays de numpy
#Esto es necesario porque Keras espera que los datos de entrada sean arrays de tipo numpy para entrenar el modelo
X_train_sequencias_2 = np.array(X_train_sequencias_padded)
X_val_sequencias_2 = np.array(X_val_sequencias_padded)
X_test_sequencias_2 = np.array(X_test_sequencias_padded)

from sklearn.preprocessing import LabelEncoder #LabelEncoder convierte etiquetas categóricas en valores numéricos
from tensorflow.keras.utils import to_categorical #to_categorical convierte etiquetas numéricas en representaciones One-Hot, que son necesarias para problemas de clasificación multiclase

#Aquí se crea una instancia de LabelEncoder para usarlo en los siguientes pasos
label_encoder = LabelEncoder()

#Codificamos las etiquetas de las clases en formato numérico usando el codificador de etiquetas (LabelEncoder)
# Esto es necesario porque el modelo de clasificación requiere que las etiquetas estén en formato numérico (enteros) en lugar de texto
y_train_etiquetas_codificadas = label_encoder.fit_transform(nuevo_y_train)

#Transformamos las etiquetas de validación y prueba utilizando el mismo mapeo aprendido con el conjunto de entrenamiento
#Esto asegura consistencia entre los conjuntos

y_val_etiquetas_codificadas = label_encoder.transform(y_val)
y_test_etiquetas_codificadas = label_encoder.transform(y_test)

#Convertimos las etiquetas codificadas en formato "one-hot" utilizando la función to_categorical
# Esto es necesario para que el modelo pueda clasificar las instancias en múltiples categorías.
# Establecemos num_classes=6 porque hay 6 categorías posibles (en este caso, emociones)
y_train_one_hot = to_categorical(y_train_etiquetas_codificadas, num_classes=6)
y_val_one_hot = to_categorical(y_val_etiquetas_codificadas, num_classes=6)
y_test_one_hot = to_categorical(y_test_etiquetas_codificadas, num_classes=6)

# Convertimos los arrays resultantes en objetos numpy para facilitar su manipulación durante el entrenamiento del modelo
y_train_one_hot_2 = np.array(y_train_one_hot)
y_val_one_hot_2 = np.array(y_val_one_hot)
y_test_one_hot_2 = np.array(y_test_one_hot)

#Entrenemos una red recurrente simple utilizando una capa de Embedding y una capa de SimpleRNN

#Importamos las capas necesarias para el modelo
from keras.layers import Dense
from keras.layers import Embedding
from keras.layers import SimpleRNN
from keras.models import Sequential
from keras.layers import Dropout

#Definimos la dimensión de los embeddings
embedding_dim=100

#Creamos el modelo RNN
model = Sequential()
model.add(Embedding(max_features, embedding_dim)) #La capa de embedding convierte los índices de palabras en vectores densos de dimensión 'embedding_dim'
model.add(Dropout(0.5)) #Añadimos una capa Dropout para evitar sobreajuste, eliminando asì el 50% de las conexiones
model.add(SimpleRNN(64)) #Esta es una capa recurrente simple con 64 unidades para procesar secuencias temporales
model.add(Dropout(0.5)) #otra capa de Dropout
model.add(Dense(6, activation='softmax')) #Capa densa totalmente conectada con 6 salidas (una por clase) y activación 'softmax'
#softmax genera una probabilidad para cada clase

model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])

early_stopping = keras.callbacks.EarlyStopping(
    patience=5,
    min_delta=0.001,
    restore_best_weights=True,
)
history = model.fit(X_train_sequencias_2, y_train_one_hot_2,
                    epochs=10,
                    batch_size=128,
                    validation_data=(X_val_sequencias_2, y_val_one_hot_2),
                    callbacks=[early_stopping],
                    verbose=2)

# Este código visualiza, en forma de grafico, las métricas de entrenamiento y validación (precisión y pérdida) a lo largo de las épocas,
# permitiendo analizar el rendimiento del modelo y detectar posibles problemas como sobreajuste o subajuste

import matplotlib.pyplot as plt

acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.legend()

plt.figure()

plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()

score = model.evaluate(X_test_sequencias_2, y_test_one_hot_2, verbose=1)
print("Accuracy: ", score[1])

#Importamos la función para calcular la matriz de confusión
from sklearn.metrics import confusion_matrix

#Obtenemos las predicciones del modelo (probabilidades para cada clase)
y_preds = model.predict(X_test_sequencias_2)

# Convertimos las probabilidades en clases
# argmax nos devuelve el índice de la clase con la probabilidad más alta
y_preds_classes = y_preds.argmax(axis=1)

#convertimos las etiquetas de una representación one-hot encoding a sus correspondientes clases numéricas
y_test_classes = y_test_one_hot_2.argmax(axis=1)

# Calculamos la matriz de confusión entre las etiquetas reales y las predicciones
cm = confusion_matrix(y_test_classes, y_preds_classes)

print(cm)

import seaborn as sns

#Calculamos la matriz de confusión
cm = confusion_matrix(y_test_classes, y_preds_classes)

#Creamos un gráfico de la matriz de confusión
plt.figure(figsize=(8, 6)) #Esta linea de codigo establece el tamaño de la figura
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=True, yticklabels=True)

#Añadimos etiquetas y título
plt.xlabel('Clase Predicha')
plt.ylabel('Clase Real')
plt.title('Matriz de Confusión')

#Muestra el gráfico
plt.show()

"""La matriz de confusión es una herramienta que permite analizar el rendimiento de un modelo de clasificación. Cada fila representa las clases reales (etiquetas correctas), mientras que cada columna muestra las clases predichas por el modelo. La diagonal principal indica las predicciones correctas para cada clase: cuanto más oscura sea una celda en esta diagonal, mayor será el número de aciertos. Por otro lado, las celdas fuera de la diagonal muestran los errores de clasificación, es decir, cuántos ejemplos de una clase real fueron clasificados como otra.

Desde los valores de la matriz de confusión se calculan métricas como la precisión, el recall, la exactitud (accuracy) y el F1-score, que generalmente se incluyen en el classification report; una herramienta útil para evaluar el rendimiento del modelo en cada clase.
"""

from sklearn.metrics import classification_report

#Imprimimos el informe de clasificación, que incluye métricas como precisión, recall y F1-score para cada clase
print(classification_report(y_test_classes, y_preds_classes))

"""Al examinar el classification report, podemos observar los resultados de las métricas de precisión, recall y F1-score para cada una de las 6 clases."""

#En el siguiente código entrenamos una red neuronal LSTM (Long Short-Term Memory)
#LSTM es una variante de las redes neuronales recurrentes (RNN) diseñada para aprender dependencias a largo plazo en secuencias de datos

from keras.layers import LSTM

model_1 = Sequential()
model_1.add(Embedding(max_features, embedding_dim))
model_1.add(LSTM(64)) #Capa LSTM con 64 unidades
model_1.add(Dense(6, activation='softmax'))

model_1.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['acc'])

early_stopping = keras.callbacks.EarlyStopping(
    patience=5,
    min_delta=0.001,
    restore_best_weights=True,
)
history = model_1.fit(X_train_sequencias_2, y_train_one_hot_2,
                    epochs=10,
                    batch_size=128,
                    validation_data=(X_val_sequencias_2, y_val_one_hot_2),
                    callbacks=[early_stopping],
                    verbose=2)

import matplotlib.pyplot as plt

acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.legend()

plt.figure()

plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()

score_1 = model_1.evaluate(X_test_sequencias_2, y_test_one_hot_2, verbose=1)
print("Accuracy: ", score_1[1])

from sklearn.metrics import confusion_matrix

y_preds = model_1.predict(X_test_sequencias_2)
y_preds_classes = y_preds.argmax(axis=1)
y_test_classes = y_test_one_hot_2.argmax(axis=1)

cm_1 = confusion_matrix(y_test_classes, y_preds_classes)

print(cm_1)

import seaborn as sns

cm_1 = confusion_matrix(y_test_classes, y_preds_classes)

plt.figure(figsize=(8, 6))
sns.heatmap(cm_1, annot=True, fmt="d", cmap="Blues", xticklabels=True, yticklabels=True)

plt.xlabel('Clase Predicha')
plt.ylabel('Clase Real')
plt.title('Matriz de Confusión ')

plt.show()

from sklearn.metrics import classification_report

print(classification_report(y_test_classes, y_preds_classes))

#El siguiente código implementa y entrena una red neuronal recurrente bidireccional con una capa LSTM

from keras import backend as K
K.clear_session() #Limpiamos la sesión de Keras para liberar recursos y evitar problemas con la memoria durante el entrenamiento de modelos nuevos

from tensorflow.keras import layers
from tensorflow.keras.models import Sequential

model_2 = Sequential()
model_2.add(layers.Embedding(max_features, embedding_dim))
model_2.add(layers.Bidirectional(layers.LSTM(64))) #Convierte la capa LSTM en bidireccional, lo que significa que procesa la secuencia tanto de izquierda a derecha como de derecha a izquierda
model_2.add(layers.Dropout(0.5))
model_2.add(layers.Dense(6, activation='softmax'))

model_2.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])

early_stopping = keras.callbacks.EarlyStopping(
    patience=5,
    min_delta=0.001,
    restore_best_weights=True,
)

history = model_2.fit(X_train_sequencias_2, y_train_one_hot_2,
                    epochs=10,
                    batch_size=128,
                    validation_data=(X_val_sequencias_2, y_val_one_hot_2),
                    callbacks=[early_stopping],
                    verbose=2)

import matplotlib.pyplot as plt

acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.legend()

plt.figure()

plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()

score_2 = model_2.evaluate(X_test_sequencias_2, y_test_one_hot_2, verbose=1)
print("Accuracy: ", score_2[1])

from sklearn.metrics import confusion_matrix

y_preds = model_2.predict(X_test_sequencias_2)

y_preds_classes = y_preds.argmax(axis=1)

y_test_classes = y_test_one_hot_2.argmax(axis=1)

cm_2 = confusion_matrix(y_test_classes, y_preds_classes)

print(cm_2)

import seaborn as sns

cm_2 = confusion_matrix(y_test_classes, y_preds_classes)


plt.figure(figsize=(8, 6))
sns.heatmap(cm_2, annot=True, fmt="d", cmap="Blues", xticklabels=True, yticklabels=True)


plt.xlabel('Classe Predicha')
plt.ylabel('Clase Real')
plt.title('Matriz de Confusión')


plt.show()

from sklearn.metrics import classification_report

print(classification_report(y_test_classes, y_preds_classes))

"""Al analizar y comparar los informes de clasificación de los tres modelos, observamos que la Simple RNN ha obtenido resultados relativamente buenos, con una precisión media del 75% entre las 6 clases. La precisión y el recall están bastante equilibrados, pero el F1-score, que refleja la media armónica entre precisión y recall, es más bajo en comparación con los otros modelos. El LSTM, por otro lado, muestra una mejora con respecto a la Simple RNN, alcanzando una precisión media del 79%. En este modelo el recall también ha mejorado, lo que lleva a un F1-score más alto. Estos valores indican que el LSTM gracias a su capacidad para retener información a largo plazo, supera a la Simple RNN, que tiene dificultades al procesar secuencias largas y complejas. El último modelo, la Red Recurrente Bidireccional, ha obtenido el mejor rendimiento, con una precisión media del 81%. Todas las métricas (precisión, recall y F1-score) presentan los valores más altos entre los tres modelos, lo que sugiere que la bidireccionalidad mejora significativamente la capacidad del modelo para comprender el contexto de las secuencias, lo que se traduce en un mejor rendimiento general.







"""